{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Research Paper Implementation - An Introduction to Convolutional Neural Networks.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "W5I4ykMOvmzj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# An Introduction to Convolutional Neural Networks\n",
        "\n",
        "This is the implementation of [this](https://arxiv.org/pdf/1511.08458.pdf) research paper on Introduction to Convolution Neural Network by Keiron O’Shea and Ryan Nash.\n"
      ]
    },
    {
      "metadata": {
        "id": "GBoJPaWYv6Jy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Artificial Neural Network(ANN)\n",
        "ANNs are processing units which was inspired from the biological neural system of human brain. ANNs consists of a large number of interconnected computation units which works collectively to learn from the imput data to optimise the output.\n",
        "![](https://cdn-images-1.medium.com/max/824/1*eBMwpBBboAXgqsawwOKkPw.png)\n",
        "\n",
        "We load the input, a multidimensional vector to the input layer of the Neural Network, which will be distributed to the hidden layers.The hidden layer will make decision from previous layers and see how a change in characteristic of the node will will improve the output, this is called learning. (adapting itself by getting the input and trying to decide the output with generalization).\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "B-le7cwJ5irw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Convolutional Neural Network(CNNs)\n",
        "CNNs are mostly used in the field of pattern recognition within images.This helps to encode image-specific features, making the network more suited for image focused tasks.<br>\n",
        "\n",
        "Traditional ANNs can still be used for image base tasks, but one of the problem is the computation complexity requirement in ANNs for images.<br>\n",
        "A basic MNIST dataset has 28x28 images, so the first imput layer itself should have 28x28x1 = 784 weights.\n",
        "Just think about a colour image which whose size is 3461 x 2266, that wll be 3661x2266x3 = 24,887,478 parameters in the first input layer.\n",
        "And for the network to learn the image patters for the specific output , it will need more layers that just a single input layer.\n",
        "<br><br>\n",
        "If in ideal case , you have unlimited computation power to use any ANN of any size, there also comes a problem of [overfitting](https://en.wikipedia.org/wiki/Overfitting). More if the layers and nodes, more better will you network work on the training set, but gives poor performance on test set, due to overfitting. \n",
        "<br><br>\n",
        "So, we need a model which is computationaly inexpensive and gives us good accuracy on both training and testing set.\n"
      ]
    },
    {
      "metadata": {
        "id": "UNoPKQBN9NWD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## CNN Archintecture\n",
        "![](https://s3.amazonaws.com/cdn.ayasdi.com/wp-content/uploads/2018/06/21100605/Fig2GCNN1.png)\n",
        "\n",
        "CNN comprises of 3 layers. \n",
        "1. Convolution Layer\n",
        "2. Polling Layer\n",
        "3. Fully-Connected Layer\n",
        "\n",
        "Convolution layer will determine the output of neurons of which are connected to local regions of the input through the calculation of the scalar product between their weights and the region connected to the input volume. The rectified linear unit (commonly shortened to ReLu) aims to apply an ’elementwise’ activation function such as sigmoid to the output of the\n",
        "activation produced by the previous layer.\n",
        "\n",
        "The pooling layer will then simply perform downsampling along the spatial dimensionality of the given input, further reducing the number of parameters within that activation\n",
        "\n",
        "The fully-connected layers will then perform the same duties found in standard ANNs and attempt to produce class scores from the activations, to be used for classification. It is also suggested that ReLu may be used between these layers, as to improve performance.\n",
        "\n",
        "![](https://www.researchgate.net/profile/Holger_Roth/publication/264160750/figure/fig3/AS:296012620025856@1447586316051/The-proposed-convolution-neural-network-consists-of-two-convolutional-layers-max-pooling.png)"
      ]
    },
    {
      "metadata": {
        "id": "l-_Adcoz_XRw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Implementation of Convolutional Neural Network\n",
        "\n",
        "I will implement the convolutional neural network froms cratch using only basic libraries like numpy(for computational functions), matplotlib(for visualization).<br>\n",
        "Although CNNs can now be implemented very easily and effectively using packahes like Keras, Tensorflow, Pytorch..etc."
      ]
    },
    {
      "metadata": {
        "id": "-3T-4aXC_5jG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Importing Libraries & setting up library parameters "
      ]
    },
    {
      "metadata": {
        "id": "nxb_XeyO_b_h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (5.0, 4.0) # set default size of plots\n",
        "plt.rcParams['image.interpolation'] = 'nearest'\n",
        "plt.rcParams['image.cmap'] = 'gray'\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "np.random.seed(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YAioF8CZAXjw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Convolution layer\n",
        "\n",
        "Convolution is a mathematical operation.\n",
        "In mathematics (and, in particular, functional analysis) convolution is a mathematical operation on two functions (f and g) to produce a third function that expresses how the shape of one is modified by the other.--WIKI\n"
      ]
    },
    {
      "metadata": {
        "id": "GF-JZgn9ADV_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#simple convolution function\n",
        "def single_convolution(a_prev, W, b):\n",
        "    s = a_prev * W\n",
        "    Z = np.sum(s)\n",
        "    Z = Z + float(b)\n",
        "    return Z"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OUOzqn8sBcgj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5909d5ef-92bd-426f-e19d-34b06c6ad757"
      },
      "cell_type": "code",
      "source": [
        "# lets try the function\n",
        "a = np.random.randn(5,5,1)\n",
        "W = np.random.randn(5,5,1)\n",
        "b = np.random.randn(1,1,1)\n",
        "\n",
        "print('Z = sum(a * W) + b =',single_convolution(a, W, b))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Z = sum(a * W) + b = -5.058783760414956\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2OUdssbvKE3-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# we need a function to pad the matrix\n",
        "def pad_matrix(X, pad):\n",
        "    X_pad = np.pad(X,((0,0),(pad,pad),(pad,pad),(0,0)),'constant',constant_values = 0)\n",
        "    return X_pad"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nx8R8L0xB0bF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Single Convolution Layer\n",
        "\n",
        "def single_conv_layer(A_prev, W, b, stride_pad):\n",
        "  (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape #getting dimension of previous layer\n",
        "  (w, w, n_C_prev, n_C) = W.shape\n",
        "  \n",
        "  # getting stride and pad value from the dictionary\n",
        "  stride = stride_pad['stride']\n",
        "  pad = stride_pad['pad']\n",
        "  \n",
        "  # setting up dimension of the output\n",
        "  n_H = np.floor((n_H_prev - w + 2*pad)/stride)+1\n",
        "  n_W = np.floor((n_W_prev - w + 2*pad)/stride)+1\n",
        "  \n",
        "  #initializing output vector with 0s\n",
        "  Z = np.zeros((m, int(n_H), int(n_W), int(n_C)))\n",
        "  \n",
        "  # padding the previous layer\n",
        "  A_pad = pad_matrix(A_prev, pad)\n",
        "  \n",
        "  # iterate and apply the convolution operation\n",
        "  for i in range(m):\n",
        "    a = A_pad[i] #getting each example\n",
        "    for h in range(int(n_H)):\n",
        "      for wi in range(int(n_W)):\n",
        "        for c in range(int(n_C)):\n",
        "          y_ini = h * stride\n",
        "          y_end = y_ini + w\n",
        "\n",
        "          x_ini = wi * stride\n",
        "          x_end = x_ini + w\n",
        "\n",
        "          a_conv_part = a[y_ini:y_end, x_ini:x_end,:]\n",
        "          Z[i, h, wi, c] = single_convolution(a_conv_part, W[:,:,:,c], b[:,:,:,c])\n",
        "  params = (A_prev, W, b, stride_pad) \n",
        "  return Z, params\n",
        "            \n",
        "            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8PG1AMAKMoBX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "83a2c053-7501-47ed-8c2a-157695b9ed74"
      },
      "cell_type": "code",
      "source": [
        "np.random.seed(1)\n",
        "A_prev = np.random.randn(10,4,4,3)\n",
        "W = np.random.randn(2,2,3,8)\n",
        "b = np.random.randn(1,1,1,8)\n",
        "pad_stride = {\"pad\" : 2, \"stride\": 2}\n",
        "\n",
        "Z, cache_conv = single_conv_layer(A_prev, W, b, pad_stride)\n",
        "print(\"Z = \", np.mean(Z))\n",
        "print(\"Z[3,2,1] =\", Z[3,2,1])"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Z =  0.048995203528855794\n",
            "Z[3,2,1] = [-0.61490741 -6.7439236  -2.55153897  1.75698377  3.56208902  0.53036437\n",
            "  5.18531798  8.75898442]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "irHVSffaKB-H",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![](https://hub.coursera-notebooks.org/user/cfpitxpxxwzbxkrumhshmg/notebooks/week1/images/Convolution_schematic.gif)\n",
        "\n",
        "This is what the above function does."
      ]
    },
    {
      "metadata": {
        "id": "xl5qQY03LHgj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Pooling Layer"
      ]
    },
    {
      "metadata": {
        "id": "B1st5fdDKCc5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# pooling function\n",
        "def pooling_layer(A_prev, stride_f, mode = \"max\"):\n",
        "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
        "    f = stride_f[\"f\"]\n",
        "    stride = stride_f[\"stride\"]\n",
        "    \n",
        "    n_H = int(1 + (n_H_prev - f) / stride)\n",
        "    n_W = int(1 + (n_W_prev - f) / stride)\n",
        "    n_C = n_C_prev\n",
        "    \n",
        "    A = np.zeros((m, n_H, n_W, n_C))              \n",
        "    \n",
        "    for i in range(m):         \n",
        "        for h in range(n_H):  \n",
        "            for w in range(n_W):          \n",
        "                for c in range (n_C):       \n",
        "                    \n",
        "                    vert_start = h * stride\n",
        "                    vert_end = vert_start + f\n",
        "                    horiz_start = w * stride\n",
        "                    horiz_end = horiz_start + f\n",
        "                    \n",
        "                    a_prev_slice = A_prev[i][vert_start:vert_end, horiz_start:horiz_end, :]\n",
        "                    \n",
        "                    if mode == \"max\":\n",
        "                        A[i, h, w, c] = np.max(a_prev_slice)\n",
        "                    elif mode == \"average\":\n",
        "                        A[i, h, w, c] = np.mean(a_prev_slice)\n",
        "    cache = (A_prev, hparameters)\n",
        "\n",
        "    return A, cache"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XGxciDhWOfm6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "1c9eeb4b-e435-4e3c-8afd-ae056a38a146"
      },
      "cell_type": "code",
      "source": [
        "A_prev = np.random.randn(2, 4, 4, 3)\n",
        "hparameters = {\"stride\" : 2, \"f\": 3}\n",
        "\n",
        "A, cache = pooling_layer(A_prev, hparameters)\n",
        "print(\"mode of layer is max\")\n",
        "print(\"A =\", A)\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mode of layer is max\n",
            "A = [[[[1.96710175 1.96710175 1.96710175]]]\n",
            "\n",
            "\n",
            " [[[2.52832571 2.52832571 2.52832571]]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GLY5bf8mL7hL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![](https://cdn-images-1.medium.com/max/1200/1*q0lk6B6gzvsSQSDn-20zJA.png)"
      ]
    },
    {
      "metadata": {
        "id": "sBynfz7YO0MP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Fully connected layer\n",
        "\n",
        "Fully connected layer is same as ANNs. we take the pooled box of values and make it into a single layer of NN.\n",
        "\n",
        "![](http://www.jpathinformatics.org/articles/2017/8/1/images/JPatholInform_2017_8_1_1_201108_f3.jpg)\n",
        "\n",
        "Then continue adding new layers of fully connected layer is neeeded , else use the activation to predict the output."
      ]
    },
    {
      "metadata": {
        "id": "BV4kchWnPZm6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### The final Model\n",
        "\n",
        "The model will look like\n",
        "<pre>CONV-->POOL-->CONV--->POOL..........-->CONV-->POOL-->FNN-->ACTIVATION-->PREDICTION</pre>\n",
        "CONV- Convolution layer\n",
        "POOL - Pooling Layer\n",
        "FNN - Fully Connected layer\n"
      ]
    },
    {
      "metadata": {
        "id": "9hP7afjTL6ur",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}